# AGI Trinity - Continual Learning AGI

> "ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì§„í™”í•˜ëŠ” ë¹„ì „-ì–¸ì–´ AGI ì‹œìŠ¤í…œ"

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LFM2-VL](https://img.shields.io/badge/Model-LFM2--VL--1.6B-purple.svg)](https://huggingface.co/LiquidAI/LFM2-VL-1.6B)

## ğŸ§  ê°œìš”

AGI TrinityëŠ” **LiquidAIì˜ LFM2-VL-1.6B** ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ **ì§€ì†í•™ìŠµ(Continual Learning) AGI ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•

| ê¸°ëŠ¥ | ì„¤ëª… |
|------|------|
| ğŸ–¼ï¸ **ë©€í‹°ëª¨ë‹¬** | í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì´í•´ |
| ğŸ“š **ì§€ì†í•™ìŠµ** | ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµ |
| ğŸ§  **ì¥ê¸° ë©”ëª¨ë¦¬** | í•™ìŠµí•œ ê°œë…ê³¼ ì§€ì‹ì„ ì €ì¥ |
| âš¡ **ë¡œì»¬ ì‹¤í–‰** | ì™¸ë¶€ API ì—†ì´ ë¡œì»¬ì—ì„œ ì‹¤í–‰ |
| ğŸ¯ **ì ì‘í˜•** | ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œ ê°œì„  |

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AGI Trinity                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   User      â”‚â”€â”€â”€â–¶â”‚  Multimodal â”‚â”€â”€â”€â–¶â”‚   LFM2-VL   â”‚     â”‚
â”‚  â”‚   Input     â”‚    â”‚   Engine    â”‚    â”‚   Model     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                                       â”‚            â”‚
â”‚        â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚            â–¼                                       â”‚
â”‚        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚        â”‚     â”‚  Response   â”‚                               â”‚
â”‚        â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚        â”‚            â”‚                                       â”‚
â”‚        â–¼            â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     Continual Learning Engine   â”‚                       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚  â”‚ â€¢ Experience Replay Buffer      â”‚                       â”‚
â”‚  â”‚ â€¢ Curriculum Scheduler          â”‚                       â”‚
â”‚  â”‚ â€¢ Knowledge Consolidator        â”‚                       â”‚
â”‚  â”‚ â€¢ EWC (ë§ê° ë°©ì§€)                â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                    â”‚                                        â”‚
â”‚                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚       Long-Term Memory          â”‚                       â”‚
â”‚  â”‚  â€¢ Knowledge Graph              â”‚                       â”‚
â”‚  â”‚  â€¢ Learned Concepts             â”‚                       â”‚
â”‚  â”‚  â€¢ Model Checkpoints            â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ ì„¤ì¹˜

### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
git clone https://github.com/hwkim3330/agi.git
cd agi
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# Python íŒ¨í‚¤ì§€
pip install -r requirements.txt

# PyTorch (CUDA ë²„ì „ì— ë§ê²Œ ì„¤ì¹˜)
# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CPU only
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìë™)

ì²« ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ LFM2-VL-1.6B ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤ (~3GB).

## ğŸš€ ì‚¬ìš©ë²•

### CLI ëª…ë ¹ì–´

```bash
# ì§ˆë¬¸í•˜ê¸°
python agi.py ask "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"

# ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì§ˆë¬¸
python agi.py ask "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?" --image ./photo.jpg

# ëŒ€í™”í˜• ì±„íŒ…
python agi.py chat

# í”¼ë“œë°± ì œê³µ (í•™ìŠµ ê°œì„ )
python agi.py feedback abc123 --quality 0.9 --correction "ë” ë‚˜ì€ ë‹µë³€..."

# íŠ¹ì • ì£¼ì œ ìê¸°í•™ìŠµ
python agi.py learn "ì–‘ìì»´í“¨íŒ…" --depth 5

# ì§€ì‹ ê·¸ë˜í”„ ì¡°íšŒ
python agi.py knowledge "machine learning"
python agi.py knowledge --list

# í•™ìŠµ íŠ¸ë¦¬ê±°
python agi.py train --force

# ìƒíƒœ í™•ì¸
python agi.py status

# ë‚´ë³´ë‚´ê¸°
python agi.py export agi_backup.json
```

### Python API

```python
import asyncio
from agents.lfm2_adapter import LFM2VLAdapter, LFM2Config
from core.continual_learning import ContinualLearningEngine

async def main():
    # AGI ì´ˆê¸°í™”
    config = LFM2Config(
        model_id="LiquidAI/LFM2-VL-1.6B",
        enable_continual_learning=True
    )
    agi = LFM2VLAdapter(lfm2_config=config)
    learning = ContinualLearningEngine(model_adapter=agi)

    # ëª¨ë¸ ë¡œë“œ
    await agi.load_model()

    # ì§ˆë¬¸
    response = await agi.execute("What is machine learning?")
    print(response.content)

    # ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì§ˆë¬¸
    response = await agi.execute(
        "Describe this image",
        images=["./photo.jpg"]
    )

    # í”¼ë“œë°± ì œê³µ
    exp_id = await learning.record_interaction(
        prompt="What is ML?",
        response=response.content
    )
    await learning.provide_feedback(exp_id, quality_score=0.9)

    # í•™ìŠµ
    await learning.trigger_training()

asyncio.run(main())
```

## ğŸ“ ì§€ì†í•™ìŠµ ì‹œìŠ¤í…œ

### ê²½í—˜ ì¬ìƒ ë²„í¼ (Experience Replay)

ìƒí˜¸ì‘ìš©ì„ ì €ì¥í•˜ê³  ìš°ì„ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

```python
# ê³ í’ˆì§ˆ ê²½í—˜ì— ë†’ì€ ìš°ì„ ìˆœìœ„
await learning.provide_feedback(
    experience_id="abc123",
    quality_score=0.95,
    correction="ê°œì„ ëœ ì‘ë‹µ..."
)
```

### ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ

ì‰¬ìš´ ê²ƒì—ì„œ ì–´ë ¤ìš´ ê²ƒìœ¼ë¡œ ì ì§„ì  í•™ìŠµ:

```
Level 1 (0.3) â†’ Level 2 (0.5) â†’ Level 3 (0.7) â†’ Level 4 (0.9)
```

### EWC (Elastic Weight Consolidation)

ì´ì „ì— í•™ìŠµí•œ ì§€ì‹ì„ ë³´ì¡´í•˜ë©´ì„œ ìƒˆë¡œìš´ ê²ƒì„ í•™ìŠµ:

```
Loss = Task_Loss + Î» * Î£ Fisher_i * (Î¸_i - Î¸*_i)Â²
```

### ì§€ì‹ ê·¸ë˜í”„

í•™ìŠµí•œ ê°œë…ë“¤ì„ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥:

```json
{
  "concept_id": {
    "name": "Machine Learning",
    "definition": "...",
    "examples": ["supervised", "unsupervised"],
    "related": ["AI", "Deep Learning"],
    "access_count": 42
  }
}
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
agi/
â”œâ”€â”€ agi.py                      # ë©”ì¸ CLI
â”œâ”€â”€ trinity.py                  # ë ˆê±°ì‹œ CLI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ lfm2_config.yaml       # LFM2 ì„¤ì •
â”‚   â””â”€â”€ agents.yaml            # ì—ì´ì „íŠ¸ ì„¤ì •
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base.py                # ê¸°ë³¸ ì–´ëŒ‘í„°
â”‚   â”œâ”€â”€ lfm2_adapter.py        # LFM2-VL ì–´ëŒ‘í„°
â”‚   â””â”€â”€ ...
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ continual_learning.py  # ì§€ì†í•™ìŠµ ì—”ì§„
â”‚   â”œâ”€â”€ multimodal.py          # ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
â”‚   â”œâ”€â”€ consensus.py           # í•©ì˜ ì—”ì§„
â”‚   â””â”€â”€ router.py              # ë¼ìš°í„°
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_continual.py     # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ tests/
```

## âš™ï¸ ì„¤ì •

`config/lfm2_config.yaml`:

```yaml
model:
  id: "LiquidAI/LFM2-VL-1.6B"
  device: "auto"
  dtype: "bfloat16"

generation:
  max_new_tokens: 512
  temperature: 0.1

continual_learning:
  enabled: true
  learning_rate: 0.00001
  training_interval: 100

  lora:
    enabled: true
    r: 8
    alpha: 16
```

## ğŸ“Š ëª¨ë¸ ì •ë³´

### LFM2-VL-1.6B

| ì†ì„± | ê°’ |
|------|-----|
| íŒŒë¼ë¯¸í„° (LM) | 1.2B |
| ë¹„ì „ ì¸ì½”ë” | SigLIP2 NaFlex (400M) |
| ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ | 32,768 í† í° |
| ì •ë°€ë„ | bfloat16 |
| ì¶”ë¡  ì†ë„ | ê¸°ì¡´ VLM ëŒ€ë¹„ 2ë°° |

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **GPU**: 4GB+ VRAM (8GB+ ê¶Œì¥)
- **RAM**: 8GB+ (16GB ê¶Œì¥)
- **ì €ì¥ê³µê°„**: 10GB+
- **Python**: 3.10+

## ğŸ”§ ê°œë°œ

```bash
# í…ŒìŠ¤íŠ¸
pytest tests/ -v

# ë¦°íŠ¸
ruff check .
mypy .

# í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/train_continual.py --help
```

## ğŸ“ ë¡œë“œë§µ

- [x] LFM2-VL ëª¨ë¸ í†µí•©
- [x] ì§€ì†í•™ìŠµ ì—”ì§„
- [x] ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
- [x] ê²½í—˜ ì¬ìƒ ë²„í¼
- [x] ì§€ì‹ ê·¸ë˜í”„
- [ ] ìŒì„± ì…ì¶œë ¥
- [ ] ì›¹ UI
- [ ] ë¶„ì‚° í•™ìŠµ
- [ ] RAG í†µí•©

## ğŸ“œ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ™ ê°ì‚¬

- [Liquid AI](https://liquid.ai) - LFM2-VL ëª¨ë¸
- [Hugging Face](https://huggingface.co) - Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬

---

**"ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ë” ë‚˜ì€ AIë¡œ ì§„í™”í•©ë‹ˆë‹¤"** ğŸ§ 
